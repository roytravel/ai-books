from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
import numpy as np


iris_data = load_iris()
features = iris.data
label = iris.target
dt_clf = DecisionTreeClassifier(random_state = 156)

# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 셋별 정확도를 담을 리스트 객체 생성.
kfold = KFold(n_splits = 5)
cv_accuracy = list()
print ('붓꽃 데이터 셋 크기:', features.shape[0])

n_iter = 0

for train_index, test_index in kfold.split(features):
  # kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출
  X_train, X_test = features[train_index], features[test_index]
  Y_train, Y_test = label[train_index], label[test_index]

  # 학습 및 예측
  dt_clf.fit(X_train, Y_train)
  pred = dt_clf.predict(X_test)
  n_iter = n_iter + 1

  # 반복 시마다 정확도 측정
  accuracy = np.round(accuracy_score(Y_test, pred), 4)
  train_size = X_train.shape[0]
  test_size = X_test.shape[0]

  print ('\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))
  print ('#{0} 검증 셋 인덱스:{1}'.format(n_iter, test_index))
  cv_accuracy.append(accuracy)

# 개별 iteration 별 정확도를 합하여 평균 정확도 계산
print ('\n## 평균 검증 정확도:', np.mean(cv_accuracy))
